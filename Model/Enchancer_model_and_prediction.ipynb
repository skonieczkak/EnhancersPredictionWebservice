{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e916c769",
   "metadata": {},
   "source": [
    "## Model sici neurnonwej do rozpoznawania enchancerów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e23bebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "560292d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzenie słownika zawierający wszystkie k-mery danej długości\n",
    "def create_kmer_dict(k):\n",
    "    bases = ['A', 'C', 'G', 'T']\n",
    "    kmer_dict = {}\n",
    "    for i in range(4**k):\n",
    "        kmer = ''.join([bases[(i // (4**j)) % 4] for j in range(k)])\n",
    "        rev_comp = ''.join([{'A':'T', 'C':'G', 'G':'C', 'T':'A'}[base] for base in kmer[::-1]])\n",
    "        if kmer not in kmer_dict and rev_comp not in kmer_dict:\n",
    "            kmer_dict[kmer] = 0\n",
    "    return kmer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d7a6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzenie słownika zliczającego ilość k-merów danej sekwencji uwzględniająć odwrotną komplementarność\n",
    "def seq_kmers_dict(dna_sequence, k, kmers_dicts):\n",
    "    number_of_kmer = len(dna_sequence) - k + 1\n",
    "    for i in range(len(dna_sequence) - k + 1):\n",
    "        kmer = dna_sequence[i:i+k]\n",
    "        rc_kmer = reverse_complement(kmer)\n",
    "        if kmer in kmers_dicts:\n",
    "            kmers_dicts[kmer] += 1/number_of_kmer\n",
    "        elif rc_kmer in kmers_dicts:\n",
    "            kmers_dicts[rc_kmer] += 1/number_of_kmer\n",
    "    return kmers_dicts\n",
    "\n",
    "def reverse_complement(dna_sequence):\n",
    "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'}\n",
    "    rc_sequence = \"\"\n",
    "    for base in reversed(dna_sequence):\n",
    "        rc_sequence += complement[base]\n",
    "    return rc_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f322413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie sekwencji dna\n",
    "df_fasta = pd.DataFrame(columns=['ID', 'sequence'])\n",
    "with gzip.open(\"GRCh37.primary_assembly.genome.fa.gz\", \"rt\") as handle:\n",
    "    for record in SeqIO.parse(handle, 'fasta'):\n",
    "        identifier = record.id\n",
    "        sequence = record.seq\n",
    "        df_fasta = pd.concat([df_fasta, pd.DataFrame.from_records([{'ID':identifier, 'sequence':sequence}])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e5de0",
   "metadata": {},
   "source": [
    "# Model 5-mer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c91de01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer_dict = create_kmer_dict(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7ec8fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zbiór pozytywny\n",
    "positive_seq = list()\n",
    "with open('positive.bed') as f:\n",
    "    for line in f:\n",
    "        name, start, stop, tmp = line.split()\n",
    "        positive_seq.append(str(list(df_fasta.loc[df_fasta['ID'] == name, 'sequence'])[0][int(start)-1:int(stop)]))\n",
    "\n",
    "positive_seq = [x for x in positive_seq if 'N' not in x ]\n",
    "positive_set = [seq_kmers_dict(x, 5, kmer_dict.copy()) for x in positive_seq]\n",
    "train_x_positive = pd.DataFrame(positive_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fb0c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zbiór negatywny\n",
    "negative_seq = list()\n",
    "with open('negative.bed') as f:\n",
    "    for line in f:\n",
    "        name, start, stop = line.split()\n",
    "        negative_seq.append(str(list(df_fasta.loc[df_fasta['ID'] == name, 'sequence'])[0][int(start)-1:int(stop)]))\n",
    "\n",
    "negative_seq = [x for x in negative_seq if 'N' not in x ]\n",
    "negative_set = [seq_kmers_dict(x, 5, kmer_dict.copy()) for x in negative_seq]\n",
    "train_x_negative = pd.DataFrame(negative_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7749280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stworzenie zbioru \n",
    "train_x = pd.concat([train_x_positive, train_x_negative])\n",
    "train_y = pd.DataFrame([1]*41513 + [0]*72389)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dd7e81",
   "metadata": {},
   "source": [
    "# Model 5-mer z podziałem na zbiór treningowy i testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "438b5e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c75163af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(4321)\n",
    "model2 = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    #tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    #tf.keras.layers.Dense(70, activation=tf.nn.relu),\n",
    "                                    #tf.keras.layers.Dense(70, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "model2.compile(optimizer='adam', loss = tf.keras.losses.binary_crossentropy, metrics=[tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c5ed8d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "2492/2492 [==============================] - 7s 2ms/step - loss: 0.5673 - recall: 0.4329\n",
      "Epoch 2/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.5422 - recall: 0.5311\n",
      "Epoch 3/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.5375 - recall: 0.5399\n",
      "Epoch 4/70\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.5348 - recall: 0.5381\n",
      "Epoch 5/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.5318 - recall: 0.5401\n",
      "Epoch 6/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.5294 - recall: 0.5386\n",
      "Epoch 7/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.5271 - recall: 0.5455\n",
      "Epoch 8/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.5237 - recall: 0.5479\n",
      "Epoch 9/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.5212 - recall: 0.5501\n",
      "Epoch 10/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.5188 - recall: 0.5496\n",
      "Epoch 11/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.5167 - recall: 0.5529\n",
      "Epoch 12/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.5146 - recall: 0.5514\n",
      "Epoch 13/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.5119 - recall: 0.5537\n",
      "Epoch 14/70\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.5089 - recall: 0.5520\n",
      "Epoch 15/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.5059 - recall: 0.5594\n",
      "Epoch 16/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.5034 - recall: 0.5552\n",
      "Epoch 17/70\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.5000 - recall: 0.5586\n",
      "Epoch 18/70\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.4965 - recall: 0.5617\n",
      "Epoch 19/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.4933 - recall: 0.5667\n",
      "Epoch 20/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.4891 - recall: 0.5680\n",
      "Epoch 21/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.4865 - recall: 0.5703\n",
      "Epoch 22/70\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.4825 - recall: 0.5750\n",
      "Epoch 23/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.4787 - recall: 0.5775\n",
      "Epoch 24/70\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.4741 - recall: 0.5821\n",
      "Epoch 25/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.4704 - recall: 0.5902\n",
      "Epoch 26/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.4665 - recall: 0.5925\n",
      "Epoch 27/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.4625 - recall: 0.5932\n",
      "Epoch 28/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.4580 - recall: 0.5991\n",
      "Epoch 29/70\n",
      "2492/2492 [==============================] - 8s 3ms/step - loss: 0.4551 - recall: 0.5999\n",
      "Epoch 30/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.4491 - recall: 0.6084\n",
      "Epoch 31/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.4442 - recall: 0.6126\n",
      "Epoch 32/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.4414 - recall: 0.6163\n",
      "Epoch 33/70\n",
      "2492/2492 [==============================] - 8s 3ms/step - loss: 0.4361 - recall: 0.6243\n",
      "Epoch 34/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.4327 - recall: 0.6262\n",
      "Epoch 35/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.4278 - recall: 0.6300\n",
      "Epoch 36/70\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.4222 - recall: 0.6389\n",
      "Epoch 37/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.4172 - recall: 0.6455\n",
      "Epoch 38/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.4127 - recall: 0.6472\n",
      "Epoch 39/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.4077 - recall: 0.6540\n",
      "Epoch 40/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.4035 - recall: 0.6566\n",
      "Epoch 41/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3985 - recall: 0.6666\n",
      "Epoch 42/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3947 - recall: 0.6671\n",
      "Epoch 43/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3903 - recall: 0.6682\n",
      "Epoch 44/70\n",
      "2492/2492 [==============================] - 8s 3ms/step - loss: 0.3858 - recall: 0.6719\n",
      "Epoch 45/70\n",
      "2492/2492 [==============================] - 8s 3ms/step - loss: 0.3788 - recall: 0.6825\n",
      "Epoch 46/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.3756 - recall: 0.6834\n",
      "Epoch 47/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.3712 - recall: 0.6872\n",
      "Epoch 48/70\n",
      "2492/2492 [==============================] - 8s 3ms/step - loss: 0.3671 - recall: 0.6898\n",
      "Epoch 49/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.3636 - recall: 0.6905\n",
      "Epoch 50/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.3592 - recall: 0.6981\n",
      "Epoch 51/70\n",
      "2492/2492 [==============================] - 8s 3ms/step - loss: 0.3550 - recall: 0.7009\n",
      "Epoch 52/70\n",
      "2492/2492 [==============================] - 8s 3ms/step - loss: 0.3506 - recall: 0.7060\n",
      "Epoch 53/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.3478 - recall: 0.7090\n",
      "Epoch 54/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.3408 - recall: 0.7132\n",
      "Epoch 55/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.3398 - recall: 0.7143\n",
      "Epoch 56/70\n",
      "2492/2492 [==============================] - 8s 3ms/step - loss: 0.3345 - recall: 0.7174\n",
      "Epoch 57/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.3303 - recall: 0.7248\n",
      "Epoch 58/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3286 - recall: 0.7248\n",
      "Epoch 59/70\n",
      "2492/2492 [==============================] - 9s 4ms/step - loss: 0.3234 - recall: 0.7327\n",
      "Epoch 60/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.3212 - recall: 0.7302\n",
      "Epoch 61/70\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.3189 - recall: 0.7342\n",
      "Epoch 62/70\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3125 - recall: 0.7409\n",
      "Epoch 63/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.3096 - recall: 0.7462\n",
      "Epoch 64/70\n",
      "2492/2492 [==============================] - 8s 3ms/step - loss: 0.3074 - recall: 0.7482\n",
      "Epoch 65/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.3040 - recall: 0.7541\n",
      "Epoch 66/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.3008 - recall: 0.7521\n",
      "Epoch 67/70\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.2966 - recall: 0.7581\n",
      "Epoch 68/70\n",
      "2492/2492 [==============================] - 9s 3ms/step - loss: 0.2942 - recall: 0.7614\n",
      "Epoch 69/70\n",
      "2492/2492 [==============================] - 9s 3ms/step - loss: 0.2925 - recall: 0.7622\n",
      "Epoch 70/70\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.2908 - recall: 0.7626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26945390090>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, epochs=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1416d9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model5kmer_train_test\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model5kmer_train_test\\assets\n"
     ]
    }
   ],
   "source": [
    "model2.save('model5kmer_train_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07f71ad",
   "metadata": {},
   "source": [
    "## Metryki dla zbioru treningowego i testowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9542a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2492/2492 [==============================] - 3s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model2.predict(x_train)\n",
    "enchancer = (pred > 0.5).astype(int)\n",
    "enchcer_true = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "140d2a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8701383401688176\n",
      "0.7585624116165971\n",
      "0.8676766481240383\n",
      "0.809458962090541\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(enchcer_true, enchancer ))\n",
    "print(recall_score(enchcer_true, enchancer ))\n",
    "print(precision_score(enchcer_true, enchancer ))\n",
    "print(f1_score(enchcer_true, enchancer ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9969fbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model2.predict(x_test)\n",
    "enchancer = (pred > 0.5).astype(int)\n",
    "enchcer_true = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43d19851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7101050598460683\n",
      "0.5329872204472843\n",
      "0.621785314945956\n",
      "0.5739721314295544\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(enchcer_true, enchancer ))\n",
    "print(recall_score(enchcer_true, enchancer ))\n",
    "print(precision_score(enchcer_true, enchancer ))\n",
    "print(f1_score(enchcer_true, enchancer ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865008df",
   "metadata": {},
   "source": [
    "# Drugi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3758b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5800ff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(4321)\n",
    "model2 = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    #tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    #tf.keras.layers.Dense(70, activation=tf.nn.relu),\n",
    "                                    #tf.keras.layers.Dense(70, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "model2.compile(optimizer='adam', loss = tf.keras.losses.binary_crossentropy, metrics=[tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a3fe5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2492/2492 [==============================] - 8s 3ms/step - loss: 0.5674 - recall: 0.4461\n",
      "Epoch 2/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.5435 - recall: 0.5290\n",
      "Epoch 3/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.5387 - recall: 0.5380\n",
      "Epoch 4/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.5358 - recall: 0.5355\n",
      "Epoch 5/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.5326 - recall: 0.5435\n",
      "Epoch 6/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.5304 - recall: 0.5415\n",
      "Epoch 7/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.5279 - recall: 0.5456\n",
      "Epoch 8/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.5241 - recall: 0.5497\n",
      "Epoch 9/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.5220 - recall: 0.5513\n",
      "Epoch 10/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.5193 - recall: 0.5533\n",
      "Epoch 11/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.5169 - recall: 0.5547\n",
      "Epoch 12/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.5145 - recall: 0.5532\n",
      "Epoch 13/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.5114 - recall: 0.5559\n",
      "Epoch 14/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.5081 - recall: 0.5577\n",
      "Epoch 15/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.5048 - recall: 0.5614\n",
      "Epoch 16/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.5017 - recall: 0.5650\n",
      "Epoch 17/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.4983 - recall: 0.5658\n",
      "Epoch 18/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.4958 - recall: 0.5655\n",
      "Epoch 19/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.4916 - recall: 0.5691\n",
      "Epoch 20/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.4870 - recall: 0.5776\n",
      "Epoch 21/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.4843 - recall: 0.5763\n",
      "Epoch 22/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.4800 - recall: 0.5803\n",
      "Epoch 23/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.4763 - recall: 0.5848\n",
      "Epoch 24/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.4717 - recall: 0.5856\n",
      "Epoch 25/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.4673 - recall: 0.5941\n",
      "Epoch 26/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.4630 - recall: 0.5982\n",
      "Epoch 27/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.4572 - recall: 0.5998\n",
      "Epoch 28/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.4527 - recall: 0.6062\n",
      "Epoch 29/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.4491 - recall: 0.6105\n",
      "Epoch 30/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.4433 - recall: 0.6144\n",
      "Epoch 31/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.4383 - recall: 0.6202\n",
      "Epoch 32/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.4328 - recall: 0.6263\n",
      "Epoch 33/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.4296 - recall: 0.6272\n",
      "Epoch 34/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.4231 - recall: 0.6355\n",
      "Epoch 35/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.4185 - recall: 0.6384\n",
      "Epoch 36/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.4122 - recall: 0.6454\n",
      "Epoch 37/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.4081 - recall: 0.6515\n",
      "Epoch 38/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.4022 - recall: 0.6534\n",
      "Epoch 39/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3966 - recall: 0.6597\n",
      "Epoch 40/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3915 - recall: 0.6650\n",
      "Epoch 41/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3885 - recall: 0.6707\n",
      "Epoch 42/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3841 - recall: 0.6742\n",
      "Epoch 43/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3799 - recall: 0.6770\n",
      "Epoch 44/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3752 - recall: 0.6811\n",
      "Epoch 45/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3690 - recall: 0.6882\n",
      "Epoch 46/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3670 - recall: 0.6887\n",
      "Epoch 47/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3614 - recall: 0.6948\n",
      "Epoch 48/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3572 - recall: 0.6982\n",
      "Epoch 49/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3513 - recall: 0.7042\n",
      "Epoch 50/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3471 - recall: 0.7060\n",
      "Epoch 51/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3434 - recall: 0.7128\n",
      "Epoch 52/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3382 - recall: 0.7160\n",
      "Epoch 53/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3345 - recall: 0.7187\n",
      "Epoch 54/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3317 - recall: 0.7233\n",
      "Epoch 55/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3278 - recall: 0.7268\n",
      "Epoch 56/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3236 - recall: 0.7329\n",
      "Epoch 57/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3206 - recall: 0.7350\n",
      "Epoch 58/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3170 - recall: 0.7363\n",
      "Epoch 59/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3129 - recall: 0.7436\n",
      "Epoch 60/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3077 - recall: 0.7450\n",
      "Epoch 61/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.3061 - recall: 0.7455\n",
      "Epoch 62/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2992 - recall: 0.7531\n",
      "Epoch 63/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.2997 - recall: 0.7523\n",
      "Epoch 64/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.2966 - recall: 0.7571\n",
      "Epoch 65/100\n",
      "2492/2492 [==============================] - 8s 3ms/step - loss: 0.2931 - recall: 0.7606\n",
      "Epoch 66/100\n",
      "2492/2492 [==============================] - 7s 3ms/step - loss: 0.2877 - recall: 0.7621\n",
      "Epoch 67/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.2850 - recall: 0.7664\n",
      "Epoch 68/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2831 - recall: 0.7703\n",
      "Epoch 69/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2783 - recall: 0.7729\n",
      "Epoch 70/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2762 - recall: 0.7770\n",
      "Epoch 71/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2729 - recall: 0.7789\n",
      "Epoch 72/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2724 - recall: 0.7786\n",
      "Epoch 73/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2671 - recall: 0.7841\n",
      "Epoch 74/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2673 - recall: 0.7842\n",
      "Epoch 75/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2623 - recall: 0.7883\n",
      "Epoch 76/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2601 - recall: 0.7911\n",
      "Epoch 77/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2588 - recall: 0.7930\n",
      "Epoch 78/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2564 - recall: 0.7954\n",
      "Epoch 79/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2526 - recall: 0.7975\n",
      "Epoch 80/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2488 - recall: 0.8015\n",
      "Epoch 81/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2457 - recall: 0.8039\n",
      "Epoch 82/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2452 - recall: 0.8055\n",
      "Epoch 83/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2415 - recall: 0.8078\n",
      "Epoch 84/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.2400 - recall: 0.8097\n",
      "Epoch 85/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.2373 - recall: 0.8132\n",
      "Epoch 86/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2380 - recall: 0.8124\n",
      "Epoch 87/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2325 - recall: 0.8176\n",
      "Epoch 88/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2315 - recall: 0.8198\n",
      "Epoch 89/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2289 - recall: 0.8229\n",
      "Epoch 90/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2293 - recall: 0.8235\n",
      "Epoch 91/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.2240 - recall: 0.8252\n",
      "Epoch 92/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.2215 - recall: 0.8291\n",
      "Epoch 93/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2200 - recall: 0.8302\n",
      "Epoch 94/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.2214 - recall: 0.8280\n",
      "Epoch 95/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2171 - recall: 0.8313\n",
      "Epoch 96/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.2174 - recall: 0.8324\n",
      "Epoch 97/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2126 - recall: 0.8351\n",
      "Epoch 98/100\n",
      "2492/2492 [==============================] - 6s 2ms/step - loss: 0.2122 - recall: 0.8354\n",
      "Epoch 99/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.2086 - recall: 0.8377\n",
      "Epoch 100/100\n",
      "2492/2492 [==============================] - 6s 3ms/step - loss: 0.2076 - recall: 0.8400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1edecf68490>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18729f4f",
   "metadata": {},
   "source": [
    "## Metryki dla zbioru treningowego i testowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9f56572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2492/2492 [==============================] - 3s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model2.predict(x_train)\n",
    "enchancer = (pred > 0.5).astype(int)\n",
    "enchcer_true = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ffb489f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166948865560447\n",
      "0.8254751146828545\n",
      "0.937997256515775\n",
      "0.8781463271446394\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(enchcer_true, enchancer ))\n",
    "print(recall_score(enchcer_true, enchancer ))\n",
    "print(precision_score(enchcer_true, enchancer ))\n",
    "print(f1_score(enchcer_true, enchancer ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e8f0f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model2.predict(x_test)\n",
    "enchancer = (pred > 0.5).astype(int)\n",
    "enchcer_true = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0bbf2181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69237072371309\n",
      "0.5060702875399361\n",
      "0.5941485371342836\n",
      "0.546583850931677\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(enchcer_true, enchancer ))\n",
    "print(recall_score(enchcer_true, enchancer ))\n",
    "print(precision_score(enchcer_true, enchancer ))\n",
    "print(f1_score(enchcer_true, enchancer ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035cbfd8",
   "metadata": {},
   "source": [
    "# predykcja z sekwencji dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78fbc4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_seq = \"AAAGACCCCTTCACTGACATGGTGAATACACTGTGTAGGTCCAGAGACAGTGATGACAAACTAAGTTTCACAGACTTTGAATTTGGGAAGGCCAGTGAGATATCGCAGCCAAGATACCCCAGAGGCAGTGGAGCAGGGTGAATAAAGTCTCACTAGAGGGTCAGATTTGGCAAATGCGTGGGTTGCAGTTGAAGCCACAGATGTGAATTGCCGTCCAGTAAGTGTAGGGGGAGTAAAGATCTAGGATAAGGAGAGAAAGAGAAACTGGCACTGACAGAAAGAAACAGGAAGAGAAAAAGCTGACAGAAACTACATGGAACCTACCACACTCAAGGGAGGTTGGCTAATGGTGTCACGTGATGCCAGGACACCTGGCGAGTTAGGAACCTGGGAAGAGTTATTTTGTGACCTGGGCTGACAGTTTTATTAAAAGGGACAAGTGAGTGGCCAGAGTGTGAGGGGCCGAGGCAGGCCTGGCAGGAATGAGGGTGGGCTGTTAAGGTGATCTGGCTGGGCCACAGGGGCGGGGGAGAGAGGCGTTGGTTTGTCATTGTTCTTGAATTAAGCATGTTGAGTTGCCAACTACAAGATGCTA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0332cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(seq_kmers_dict(dna_seq, 5, kmer_dict.copy()), index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffc7c95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.998462"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# szansa że sekwencja jest enchancerem\n",
    "model2.predict(x)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbbf46d",
   "metadata": {},
   "source": [
    "# WebService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a613fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.load_model('model5kmer_train_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceeca75",
   "metadata": {},
   "source": [
    "## średnie długości "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c66dc017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obliczanie średnie długości\n",
    "enchancer_lengths = pd.DataFrame(columns=['name', 'lenght'])\n",
    "with open('positive_all.bed') as f:\n",
    "    for line in f:\n",
    "        name, start, stop, tmp = line.split()\n",
    "        new_row = {'name': name, 'lenght': int(stop)-int(start)+1}\n",
    "        enchancer_lengths.loc[len(enchancer_lengths)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39db9705",
   "metadata": {},
   "outputs": [],
   "source": [
    "srednie = enchancer_lengths.groupby('name')['lenght'].mean()\n",
    "srednie = srednie.round().astype(int)\n",
    "srednie = srednie[0:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93825a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "chr1     1730\n",
       "chr10    1773\n",
       "chr11    1730\n",
       "chr12    1747\n",
       "chr13    1677\n",
       "chr14    1907\n",
       "chr15    1831\n",
       "chr16    1761\n",
       "chr17    1792\n",
       "chr18    1682\n",
       "chr19    1468\n",
       "chr2     1786\n",
       "chr20    1749\n",
       "chr21    1836\n",
       "chr22    1875\n",
       "chr3     1719\n",
       "chr4     1675\n",
       "chr5     1767\n",
       "chr6     1791\n",
       "chr7     1636\n",
       "chr8     1804\n",
       "chr9     1767\n",
       "Name: lenght, dtype: int32"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srednie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e89a775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chr1', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16',\n",
       "       'chr17', 'chr18', 'chr19', 'chr2', 'chr20', 'chr21', 'chr22', 'chr3',\n",
       "       'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9'],\n",
       "      dtype='object', name='name')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srednie.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b80d8a",
   "metadata": {},
   "source": [
    "## predykcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb421720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\n",
      "4503/4503 [==============================] - 6s 1ms/step\n",
      "chr10\n",
      "2389/2389 [==============================] - 4s 2ms/step\n",
      "chr11\n",
      "2439/2439 [==============================] - 4s 2ms/step\n",
      "chr12\n",
      "2395/2395 [==============================] - 3s 1ms/step\n",
      "chr13\n",
      "2147/2147 [==============================] - 3s 1ms/step\n",
      "chr14\n",
      "1760/1760 [==============================] - 3s 2ms/step\n",
      "chr15\n",
      "1750/1750 [==============================] - 3s 2ms/step\n",
      "chr16\n",
      "1604/1604 [==============================] - 3s 2ms/step\n",
      "chr17\n",
      "1416/1416 [==============================] - 2s 2ms/step\n",
      "chr18\n",
      "1451/1451 [==============================] - 2s 2ms/step\n",
      "chr19\n",
      "1259/1259 [==============================] - 2s 1ms/step\n",
      "chr2\n",
      "4256/4256 [==============================] - 5s 1ms/step\n",
      "chr20\n",
      "1127/1127 [==============================] - 1s 1ms/step\n",
      "chr21\n",
      "820/820 [==============================] - 1s 1ms/step\n",
      "chr22\n",
      "856/856 [==============================] - 1s 1ms/step\n",
      "chr3\n",
      "3600/3600 [==============================] - 4s 1ms/step\n",
      "chr4\n",
      "3567/3567 [==============================] - 4s 1ms/step\n",
      "chr5\n",
      "3200/3200 [==============================] - 4s 1ms/step\n",
      "chr6\n",
      "2986/2986 [==============================] - 4s 1ms/step\n",
      "chr7\n",
      "3040/3040 [==============================] - 4s 1ms/step\n",
      "chr8\n",
      "2536/2536 [==============================] - 4s 1ms/step\n",
      "chr9\n",
      "2498/2498 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "web_data = pd.DataFrame(columns=['name', 'mean_lenght', 'prediction', 'prediction_percent'])\n",
    "\n",
    "for name in srednie.index:\n",
    "    print(name)\n",
    "    seq_number = len(list(df_fasta.loc[df_fasta['ID'] == name, 'sequence'])[0])//srednie[name]\n",
    "    positions = [[srednie[name]//2*i, srednie[name]//2*i + srednie[name]]  for i in range(seq_number)]\n",
    "    \n",
    "    enchancer_seq = list()\n",
    "    for seq in positions:\n",
    "        start = seq[0]\n",
    "        stop = seq[1]\n",
    "        enchancer_seq.append(str(list(df_fasta.loc[df_fasta['ID'] == name, 'sequence'])[0][int(start)-1:int(stop)]))\n",
    "        \n",
    "        \n",
    "    false_ench = seq_kmers_dict(\"AAAAA\", 5, kmer_dict.copy())\n",
    "    enchancer_data = [seq_kmers_dict(x, 5, kmer_dict.copy()) if 'N' not in x else false_ench for x in enchancer_seq]\n",
    "    enchancer_data = pd.DataFrame(enchancer_data)\n",
    "    \n",
    "    \n",
    "    prediction_percent = model2.predict(enchancer_data)\n",
    "    prediction_0_1 = (prediction_percent > 0.5).astype(int)\n",
    "    prediction_percent = [x[0] for x in prediction_percent]\n",
    "    prediction_0_1 = [x[0] for x in prediction_0_1]\n",
    "\n",
    "    \n",
    "    new_row = {'name': name, 'mean_lenght': srednie[name], 'prediction': prediction_0_1, 'prediction_percent': prediction_percent }\n",
    "    web_data.loc[len(web_data)] = new_row\n",
    "\n",
    "    \n",
    "web_data = web_data.set_index('name', drop=True)    \n",
    "web_data.to_csv('web_data.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b89a896",
   "metadata": {},
   "source": [
    "## wczytanie i zamiany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dd246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = pd.read_csv('web_data.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba488138",
   "metadata": {},
   "outputs": [],
   "source": [
    "[int(x) for x in tmp1.loc[tmp1['name'] == 'chr1']['prediction'][0][1:-1].split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c458fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3de938c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124625.3105"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_fasta.loc[df_fasta['ID'] == 'chr1']['sequence'][0])/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c1ae2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
